{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO BE RUN ONLY ONCE!\n",
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## *******************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import subprocess\n",
    "import pymc3 as pm\n",
    "import seaborn as sns\n",
    "\n",
    "import spatial_mix.hdp_utils as hdp_utils\n",
    "from spatial_mix.utils import *\n",
    "from spatial_mix.protos.py.univariate_mixture_state_pb2 import UnivariateState, UnivariateMixtureState, HdpState\n",
    "\n",
    "current_palette = sns.color_palette()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"simulation_scenario.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate data as follows: for each little square we simulate data from a 3 components mixtures\n",
    "$$ y_{ij} \\sim w_{i1} N(-5, 1) + w_{i2} N(0, 1) + w_{i3} N(5, 1)$$\n",
    "\n",
    "the weights depend on the location (x, y) of the center of the square (the orange dot)\n",
    "$$ \\widetilde{w}_{il} = \\alpha_l x_i + \\beta_l y_i \\quad l=1, 2$$\n",
    "\n",
    "finally $w_i = alr^{-1} ([\\widetilde{w}_{i1}, \\widetilde{w}_{i2}])$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_alr(x):\n",
    "    out = np.exp(np.hstack((x, 1)))\n",
    "    return out / np.sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_from_mixture(weights):\n",
    "    means = [-5, 0, 5]\n",
    "    comp = np.random.choice(3, p=weights)\n",
    "    return np.random.normal(loc=means[comp], scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = np.array([[0, 1], [1, 1], [2, 1], [3, 1], [0, 0], [1, 0], [2, 0], [3, 0]])\n",
    "centers = centers / 10\n",
    "alpha1 = 0.3\n",
    "alpha2 = -0.3\n",
    "beta1 = 0.3\n",
    "beta2 = -0.3\n",
    "\n",
    "weights = []\n",
    "for center in centers:\n",
    "    w1 = alpha1 * center[0] + beta1 * center[1]\n",
    "    w2 = alpha2 * center[0] + beta2 * center[1]\n",
    "    weights.append(inv_alr([w1, w2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dmat1 = np.zeros((8, 8))\n",
    "\n",
    "for i in range(7):\n",
    "    Dmat1[i, i+1] = 1\n",
    "    Dmat1[i+1, i] = 1\n",
    "    if (i < 4):\n",
    "        Dmat1[i, i+4] = 1\n",
    "        Dmat1[i+4, i] = 1\n",
    "    \n",
    "print(Dmat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"data/simulated_D1.csv\", Dmat1, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(8):\n",
    "    numSamples = 100\n",
    "    if i == 5:\n",
    "        numSamples = 20\n",
    "        \n",
    "    for j in range(numSamples):\n",
    "        data.append([i, simulate_from_mixture(weights[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=[\"group\", \"data\"])\n",
    "df.to_csv(\"data/simulated_data1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 0 0 0 0]\n",
      " [1 0 1 1 0 0 0 0]\n",
      " [1 1 0 1 0 0 0 0]\n",
      " [1 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 1]\n",
      " [0 0 0 0 1 0 1 1]\n",
      " [0 0 0 0 1 1 0 1]\n",
      " [0 0 0 0 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "Dmat2 = np.array([\n",
    "    [0, 1, 1, 1, 0, 0, 0, 0],\n",
    "    [1, 0, 1, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 1, 1],\n",
    "    [0, 0, 0, 0, 1, 0, 1, 1],\n",
    "    [0, 0, 0, 0, 1, 1, 0, 1],\n",
    "    [0, 0, 0, 0, 1, 1, 1, 0]\n",
    "]) \n",
    "\n",
    "print(Dmat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_group1 = np.array([0.25, 0.25, 0.5])\n",
    "w_group2 = np.array([0.4, 0.4, 0.2])\n",
    "\n",
    "weights = []\n",
    "\n",
    "data = []\n",
    "for i in range(8):\n",
    "    w = w_group1 if i < 4 else w_group2\n",
    "    weights.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(8):\n",
    "    numSamples = 1000\n",
    "#     if i == 5:\n",
    "#         numSamples = 20\n",
    "\n",
    "    for j in range(numSamples):\n",
    "        data.append([i, simulate_from_mixture(weights[i])])\n",
    "        \n",
    "# df = pd.DataFrame(data, columns=[\"group\", \"data\"])\n",
    "# df.to_csv(\"data/simulated_data2.csv\", index=False)\n",
    "# np.savetxt(\"data/simulated_D2.csv\", Dmat2, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# call C++ from terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.call(\n",
    "    \"./spatial_mix/run_from_file.out\"\n",
    "    \" data/simulated_data2.csv\"\n",
    "    \" data/simulated_D2.csv\"\n",
    "    \" data/chains_simulated2.recordio\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"./spatial_mix/run_from_file.out\"\n",
    "    \" data/simulated_data2.csv\"\n",
    "    \" data/simulated_D2.csv\"\n",
    "    \" data/chains_simulated2.recordio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run via the Python interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spatial_mix.protos.py.sampler_params_pb2 import SamplerParams\n",
    "from google.protobuf import text_format\n",
    "\n",
    "df = pd.read_csv(\"./spatial_mix/data_simulation_1.csv\")\n",
    "\n",
    "burnin = 10000\n",
    "niter = 10000\n",
    "thin = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       -2.022690\n",
       "1       -1.004620\n",
       "2       -3.468810\n",
       "3       -3.939700\n",
       "4       -2.073080\n",
       "5       -2.037240\n",
       "6       -1.624360\n",
       "7       -1.936110\n",
       "8       -1.395200\n",
       "9       -2.315390\n",
       "10      -2.897630\n",
       "11      -1.456780\n",
       "12      -0.026193\n",
       "13       1.123770\n",
       "14      -1.248010\n",
       "15      -2.138100\n",
       "16      -2.200130\n",
       "17      -2.054780\n",
       "18      -0.870412\n",
       "19      -2.444050\n",
       "20       0.017322\n",
       "21      -2.889110\n",
       "22      -1.395890\n",
       "23      -0.626187\n",
       "24      -2.663320\n",
       "25      -2.047290\n",
       "26      -1.565470\n",
       "27      -2.707800\n",
       "28      -1.916950\n",
       "29      -1.310920\n",
       "          ...    \n",
       "4970    -2.044030\n",
       "4971     5.880630\n",
       "4972    -1.404940\n",
       "4973     2.140500\n",
       "4974    -2.656720\n",
       "4975     0.102388\n",
       "4976     0.338712\n",
       "4977    -2.202290\n",
       "4978    -0.799216\n",
       "4979     0.315849\n",
       "4980     0.498536\n",
       "4981   -23.319200\n",
       "4982     1.603000\n",
       "4983    -1.860510\n",
       "4984     0.471645\n",
       "4985    -0.188141\n",
       "4986     0.285361\n",
       "4987   -10.699200\n",
       "4988   -28.484400\n",
       "4989     0.673829\n",
       "4990   -19.842100\n",
       "4991    -1.247690\n",
       "4992    -6.878190\n",
       "4993     0.228397\n",
       "4994    -0.470213\n",
       "4995     0.972315\n",
       "4996    -0.979558\n",
       "4997    18.305600\n",
       "4998     0.821408\n",
       "4999    11.146200\n",
       "Name: Data, Length: 5000, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "numGroups = max(df['Group'])+1\n",
    "datas = []\n",
    "for g in range(numGroups):\n",
    "    datas.append(df[df['Group'] == g]['Data'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 1., 1.],\n",
       "       [1., 0., 1., 1., 1.],\n",
       "       [1., 1., 0., 1., 1.],\n",
       "       [1., 1., 1., 0., 1.],\n",
       "       [1., 1., 1., 1., 0.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.ones((numGroups,numGroups))-np.identity(numGroups)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Burn-in, iter # 200  /  10000\n",
      "Burn-in, iter # 400  /  10000\n"
     ]
    }
   ],
   "source": [
    "chains = runSpatialMixtureSampler(burnin, niter, thin, W,\n",
    "                                  \"spatial_mix/resources/sampler_params.asciipb\",\n",
    "                                  datas, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot density estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/data_simulation_1.csv\")\n",
    "#chains = loadChains(\"data/chains_simulated2.recordio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datas = []\n",
    "# for g in range(8):\n",
    "#     datas.append(df[df.group == g].data.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgrid = np.linspace(-10, 10, 1000)\n",
    "dens = estimateDensities(chains, xgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "map() must have at least two arguments.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-43deddd2c790>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrue_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m          \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m          \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhell_dists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost_hellinger_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PhD/spatial_lda/spatial_mix/utils.py\u001b[0m in \u001b[0;36mpost_hellinger_dist\u001b[0;34m(estimatedDens, true, xgrid)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpost_hellinger_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimatedDens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhellinger_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimatedDens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: map() must have at least two arguments."
     ]
    }
   ],
   "source": [
    "g = 5\n",
    "true_d = weights[g][0] * norm.pdf(xgrid, -5, 1.0) + \\\n",
    "         weights[g][1] * norm.pdf(xgrid, 0.0, 1.0) + \\\n",
    "         weights[g][2] * norm.pdf(xgrid, 5.0, 1.0)\n",
    "\n",
    "hell_dists = post_hellinger_dist(dens[g], true_d, xgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(15, 8))\n",
    "axes = axes.flat\n",
    "\n",
    "for g in range(8):\n",
    "    axes[g].plot(xgrid, \n",
    "                 weights[g][0] * norm.pdf(xgrid, -5, 1.0) +\n",
    "                 weights[g][1] * norm.pdf(xgrid, 0.0, 1.0) +\n",
    "                 weights[g][2] * norm.pdf(xgrid, 5.0, 1.0))\n",
    "    axes[g].plot(xgrid, np.mean(dens[g], 0))\n",
    "    axes[g].set_ylim([0, 0.3])\n",
    "    intervals = np.array([pm.stats.hpd(dens[g][:, i], 0.05) for i in range(dens[g].shape[1])])\n",
    "    axes[g].fill_between(xgrid, intervals[:, 0], intervals[:, 1], alpha=0.3, color=current_palette[2])\n",
    "    axes[g].set_title(\"Group: {0}\".format(g))\n",
    "#     sns.kdeplot(datas[g], ax=axes[g], color=current_palette[3])\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimateds = estimateDensities(chains, datas)\n",
    "lpml(estimateds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains[0].rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot RhoChain\n",
    "rhoChain = list(map(lambda x: x.rho, chains))\n",
    "plt.plot(range(len(chains)), rhoChain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wmat = Dmat2.astype(np.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.call(\n",
    "    \"./spatial_mix/run_hdp_from_file.out\"\n",
    "    \" data/simulated_data2.csv\"\n",
    "    \" data/chains_hdp_simulated2.recordio\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdpChains = loadChains(\"data/chains_hdp_simulated2.recordio\", HdpState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgrid = np.linspace(-10, 10, 1000)\n",
    "densHdp = hdp_utils.estimateDensities(hdpChains, xgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(15, 8))\n",
    "axes = axes.flat\n",
    "\n",
    "for g in range(8):\n",
    "    axes[g].plot(xgrid, \n",
    "                 weights[g][0] * norm.pdf(xgrid, -5, 1.0) +\n",
    "                 weights[g][1] * norm.pdf(xgrid, 0.0, 1.0) +\n",
    "                 weights[g][2] * norm.pdf(xgrid, 5.0, 1.0))\n",
    "    obs = df[df[\"group\"] == g][\"data\"].values\n",
    "    # sns.kdeplot(obs, ax=axes[g])\n",
    "    axes[g].set_ylim([0, 0.3])\n",
    "    axes[g].plot(xgrid, np.mean(dens[g], 0))\n",
    "    intervals = np.array([pm.stats.hpd(densHdp[g][:, i], 0.05) for i in range(densHdp[g].shape[1])])\n",
    "    axes[g].fill_between(xgrid, intervals[:, 0], intervals[:, 1], alpha=0.3, color=current_palette[2])\n",
    "    axes[g].set_title(\"Group: {0}\".format(g))\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimatedHdp = hdp_utils.estimateDensities(hdpChains, datas)\n",
    "lpml(estimatedHdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpml(estimatedHdp[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpml(estimateds[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
